{
 "cells": [
  {
   "cell_type": "raw",
   "id": "ceb26b6d-d77d-4a43-8a72-f9758596005e",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Claude Sonnet 3.7 Programs Pac-Man\"\n",
    "description: \"Revisiting Blog #2 & 3: One Prompt. One Response. How does Claude Sonnet 3.7 fare against the PacMan prompt?\"\n",
    "author: \"Michael Li\"\n",
    "date: \"2/28/2025\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - prompting\n",
    "  - logic\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2a3e52-ab93-4936-939a-03f9053be0ec",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Revisiting Blog #5: Do LLMs Understand Physics?\n",
    "\n",
    "As of February 24th, Anthropic released their new iteration of Claude Sonnet, the 3.7 model! In honor of Blog #5, I wanted to revisit the model's one-shot capabilities in coding physics with the bouncy shapes prompt:\n",
    "\n",
    "> Program a python program that simulates random bouncy shapes dropping into a box. Make sure the shapes are effected by gravity and interact with each other. Do not use an existing package to simulate physics.\n",
    "\n",
    "### A Refresher: 3.5's performance\n",
    "![](https://media3.giphy.com/media/v1.Y2lkPTc5MGI3NjExYzltM200eWxidDVzeTc5Y2I1MzR6d3JrdGh0Y2dyazA0c3FpenZyeSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/P9lHWJmpHYmOanjECq/giphy.gif)\n",
    "\n",
    "While 3.5's performance wasn't the best out comparably to Deepseek R1 and GPT's 3o-mini-high, it impressively held its own as a much 'older' model (in the relative timeframe of LLM development lol). In blog #5, I noted that the 3.5 accounted somewhat for gravity since shapes bounced more when dropped from higher heights; however, regarding collisions, 3.5 did poorly, having the shapes stick together rather than remain bouncy.\n",
    "\n",
    "### Taking a look at 3.7's performance\n",
    "![](https://media1.giphy.com/media/v1.Y2lkPTc5MGI3NjExOHFvdXUxemhwbndyczkyN2tkYXEydHR3Z3N1ZWVyNXRoMXB4eWRwOSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/ySE4zlKEVHj8DJgVek/giphy.gif)\n",
    "It definitely does better than 3.5! But it also defintely has its own set of problems... The shapes have their own distinct 'collision' physics, which is cool, and velocity/acceleration seems to be accounted for with vertical gravity and collisions. However, there are issues with collisions and sliding at the floor of the box.\n",
    "\n",
    "Also, I want to note that Claude 3.5 wrote 136 lines of code for the prompt, while 3.7 wrote a whopping **328 lines**, which is a ~3x in lenght of code output. Reading through the code, I realized the 3.7 was structuring the code more formally, following modern programming practices like abstraction and modularity. For example, the 3.7 code had a shape class, with triangle, square, and circle subclasses (all with different behavior, rather than 3.5 having the shapes all share the same behavior). This indicates, at least to me, that Claude is improving signficantly in it's abilty to independently generate more complex code. \n",
    "\n",
    "This was pretty cool seeing the growth of Claude's model set :)\n",
    "\n",
    "Will be revisiting Pac-Man too!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c82613-964f-4a7c-b928-929f924d0be2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "citation-manager": {
   "items": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
